{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i/o\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import pickle\n",
    "import json\n",
    "# configuration\n",
    "import yaml\n",
    "# lca\n",
    "import ecospold2matrix as e2m\n",
    "import pymrio\n",
    "#import brightway2 as bw\n",
    "# type hints\n",
    "from ecospold2matrix import ecospold2matrix\n",
    "from pymrio import IOSystem\n",
    "# data science\n",
    "import pandas as pd\n",
    "# deep copy\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2. file paths\n",
    "## 0.2.1. config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../config.yaml', 'r') as filestream:\n",
    "    config = yaml.load(filestream, Loader = yaml.FullLoader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3. file paths\n",
    "## 0.3.1. directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(path_dir_data := Path(Path.home(), config['path_dir_data']))\n",
    "print(path_dir_data_raw := Path(path_dir_data, config['path_dir_data_raw']))\n",
    "print(path_dir_data_processed := Path(path_dir_data, config['path_dir_data_processed']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3.2. files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(path_file_exiobase_pymrio_io_system := Path(path_dir_data_processed, config['pymrio_class_instance']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. refactoring\n",
    "\n",
    "## 1.1. legacy: `completing_extensions()`\n",
    "\n",
    "[`pylcaio.py > lines 2498-2563`](https://github.com/OASES-project/pylcaio/blob/fa5378df55c314c2f021f4f10b675bb822b3d912/src/pylcaio.py#L2498https://github.com/OASES-project/pylcaio/blob/fa5378df55c314c2f021f4f10b675bb822b3d912/src/pylcaio.py#L2498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completing_extensions(OG_extensions, new_extensions):\n",
    "    \"\"\"Function to modify the names of the extensions of the original exiobase to match the ones resulting from the\n",
    "    matching with USEEIO. Also concatenates both original and new extensions at the end, resulting in the extended\n",
    "    exiensions.\"\"\"\n",
    "    # just remove Energy Carrier Net flows and not defined waste flows\n",
    "    OG_extensions.drop([i for i in OG_extensions.index if 'Energy Carrier Net' in i],inplace=True)\n",
    "    OG_extensions.drop(['Emissions nec - waste - undef'],inplace=True)\n",
    "    # simple sum of all values for old names pollutants, e.g., 'CH4 - non combustion - Cement production - air' => 'CH4 - air'\n",
    "    easy_match = ['CH4','N2O','SOx','NH3','HCB','NMVOC','PM10','PM2.5','TSP','Cd','Hg','Pb','Zn','PAH']\n",
    "    for pollutant in easy_match:\n",
    "        list_old_names = [i for i in OG_extensions.index if pollutant in i]\n",
    "        OG_extensions.loc[pollutant+' - air'] = OG_extensions.loc[list_old_names].sum()\n",
    "        OG_extensions.drop(list_old_names, inplace=True)\n",
    "    # hardcoded stuff\n",
    "    OG_extensions.loc['Benzo(a)pyrene - air'] = OG_extensions.loc[['Benzo(a)pyrene - combustion - air','B(a)P - non combustion - Primary aluminium production - air','B(a)P - non combustion - Production of coke oven coke - air','B(a)P - non combustion - Production of gascoke - air']].sum()\n",
    "    OG_extensions.drop(['Benzo(a)pyrene - combustion - air','B(a)P - non combustion - Primary aluminium production - air','B(a)P - non combustion - Production of coke oven coke - air','B(a)P - non combustion - Production of gascoke - air'],inplace=True)\n",
    "    OG_extensions.loc['Benzo(b)fluoranthene - air'] = OG_extensions.loc[['Benzo(b)fluoranthene - combustion - air','B(b)F - non combustion - Primary aluminium production - air','B(b)F - non combustion - Production of coke oven coke - air','B(b)F - non combustion - Production of gascoke - air']].sum()\n",
    "    OG_extensions.drop(['Benzo(b)fluoranthene - combustion - air','B(b)F - non combustion - Primary aluminium production - air','B(b)F - non combustion - Production of coke oven coke - air','B(b)F - non combustion - Production of gascoke - air'],inplace=True)\n",
    "    OG_extensions.loc['Benzo(k)fluoranthene - air'] = OG_extensions.loc[['Benzo(k)fluoranthene - combustion - air','B(k)F - non combustion - Primary aluminium production - air','B(k)F - non combustion - Production of coke oven coke - air','B(k)F - non combustion - Production of gascoke - air']].sum()\n",
    "    OG_extensions.drop(['Benzo(k)fluoranthene - combustion - air','B(k)F - non combustion - Primary aluminium production - air','B(k)F - non combustion - Production of coke oven coke - air','B(k)F - non combustion - Production of gascoke - air'],inplace=True)\n",
    "    OG_extensions.loc['CO2 - biogenic - air'] = OG_extensions.loc['CO2 - waste - biogenic - air']\n",
    "    OG_extensions.drop(['CO2 - waste - biogenic - air'],inplace=True)\n",
    "    OG_extensions.loc['Pxx - soil'] = OG_extensions.loc[['Pxx - agriculture - soil','P - agriculture - soil']].sum()\n",
    "    OG_extensions.drop(['Pxx - agriculture - soil','P - agriculture - soil'],inplace=True)\n",
    "    old_CO2_flows = [i for i in OG_extensions.index if 'CO2' in i and 'biogenic' not in i]\n",
    "    OG_extensions.loc['CO2 - air'] = OG_extensions.loc[old_CO2_flows].sum() # adds new row 'CO2 - air' and sums all CO2 flows\n",
    "    OG_extensions.drop(old_CO2_flows,inplace=True)\n",
    "    old_CO_flows = [i for i in OG_extensions.index if 'CO' in i and '2' not in i]\n",
    "    OG_extensions.loc['CO - air'] = OG_extensions.loc[old_CO_flows].sum()\n",
    "    OG_extensions.drop(old_CO_flows,inplace=True)\n",
    "    old_NOx_flows = [i for i in OG_extensions.index if 'NOx' in i or 'NOX' in i]\n",
    "    OG_extensions.loc['NOx - air'] = OG_extensions.loc[old_NOx_flows].sum()\n",
    "    OG_extensions.drop(old_NOx_flows,inplace=True)\n",
    "    old_indeno_flows = [i for i in OG_extensions.index if 'Indeno' in i]\n",
    "    OG_extensions.loc['Indeno(1,2,3-cd)pyrene - air'] = OG_extensions.loc[old_indeno_flows].sum()\n",
    "    OG_extensions.drop(old_indeno_flows,inplace=True)\n",
    "    old_PCB_flows = [i for i in OG_extensions.index if 'PCB' in i]\n",
    "    OG_extensions.loc['PCBs - air'] = OG_extensions.loc[old_PCB_flows].sum()\n",
    "    OG_extensions.drop(old_PCB_flows,inplace=True)\n",
    "    old_PCDD_flows = [i for i in OG_extensions.index if 'PCDD' in i]\n",
    "    OG_extensions.loc['PCDD_F - air'] = OG_extensions.loc[old_PCDD_flows].sum()\n",
    "    OG_extensions.drop(old_PCDD_flows,inplace=True)\n",
    "    old_As_flows = [i for i in OG_extensions.index if 'As -' in i]\n",
    "    OG_extensions.loc['As - air'] = OG_extensions.loc[old_As_flows].sum()\n",
    "    OG_extensions.drop(old_As_flows,inplace=True)\n",
    "    old_Ni_flows = [i for i in OG_extensions.index if 'Ni -' in i]\n",
    "    OG_extensions.loc['Ni - air'] = OG_extensions.loc[old_Ni_flows].sum()\n",
    "    OG_extensions.drop(old_Ni_flows,inplace=True)\n",
    "    old_Cr_flows = [i for i in OG_extensions.index if 'Cr -' in i]\n",
    "    OG_extensions.loc['Cr - air'] = OG_extensions.loc[old_Cr_flows].sum()\n",
    "    OG_extensions.drop(old_Cr_flows,inplace=True)\n",
    "    old_Cu_flows = [i for i in OG_extensions.index if 'Cu -' in i]\n",
    "    OG_extensions.loc['Cu - air'] = OG_extensions.loc[old_Cu_flows].sum()\n",
    "    OG_extensions.drop(old_Cu_flows,inplace=True)\n",
    "    old_Se_flows = [i for i in OG_extensions.index if 'Se -' in i]\n",
    "    OG_extensions.loc['Se - air'] = OG_extensions.loc[old_Se_flows].sum()\n",
    "    OG_extensions.drop(old_Se_flows,inplace=True)\n",
    "    old_N_flows = [i for i in OG_extensions.index if 'N -' in i]\n",
    "    OG_extensions.loc['N - water'] = OG_extensions.loc[old_N_flows].sum()\n",
    "    OG_extensions.drop(old_N_flows,inplace=True)\n",
    "    old_P_flows = [i for i in OG_extensions.index if 'P -' in i and 'water' in i]\n",
    "    OG_extensions.loc['P - water'] = OG_extensions.loc[old_P_flows].sum()\n",
    "    OG_extensions.drop(old_P_flows,inplace=True)\n",
    "    # after all this hardwork, concatenate with extensions\n",
    "    extended_extensions = pd.concat([OG_extensions,new_extensions])\n",
    "    return extended_extensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. new: `completing_extensions()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exiobase: IOSystem = pd.read_pickle(path_file_exiobase_pymrio_io_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Taxes less subsidies on products purchased: Total',\n",
       "       'Other net taxes on production',\n",
       "       'Compensation of employees; wages, salaries, & employers' social contributions: Low-skilled',\n",
       "       'Compensation of employees; wages, salaries, & employers' social contributions: Medium-skilled',\n",
       "       'Compensation of employees; wages, salaries, & employers' social contributions: High-skilled',\n",
       "       'Operating surplus: Consumption of fixed capital',\n",
       "       'Operating surplus: Rents on land',\n",
       "       'Operating surplus: Royalties on resources',\n",
       "       'Operating surplus: Remaining net operating surplus',\n",
       "       'Employment: Low-skilled male',\n",
       "       ...\n",
       "       'Water Withdrawal Blue - Domestic - domestic Water Withdrawal Blue',\n",
       "       'Energy Carrier Net Total', 'Energy Carrier Net NENE',\n",
       "       'Energy Carrier Net NTRA', 'Energy Carrier Net TAVI',\n",
       "       'Energy Carrier Net TMAR', 'Energy Carrier Net TOTH',\n",
       "       'Energy Carrier Net TRAI', 'Energy Carrier Net TROA',\n",
       "       'Energy Carrier Net LOSS'],\n",
       "      dtype='object', name='stressor', length=1113)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exiobase.satellite.F.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rows_based_on_row_names_conditions(\n",
    "    df: pd.DataFrame,\n",
    "    dict_row_names_conditions: dict,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes an input dataframe with an index column of row names and sums the rows specified in the rows dictionary.\n",
    "    The rows dictionary has keys that are the new row names and values that are boolean conditions on the row names of the rows to be summed.\n",
    "    Rows that are summed over are dropped from the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): input dataframe with an index column of row names\n",
    "        dict_row_names_conditions (dict): a dictionary where rows.keys() are the new row names and rows.values() are conditions on the row names of the rows to be summed\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: output dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    for new_row_name, old_rows_names_conditions in dict_row_names_conditions.items():\n",
    "        old_rows_names: list = [*df.query(old_rows_names_conditions).index]\n",
    "        df.loc[new_row_name] = df.loc[old_rows_names].sum()\n",
    "        df.drop(labels = old_rows_names, inplace=True, errors = 'ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dict_exiobase_environmental_extensions_sum_rows.json', mode = 'r', encoding = 'utf-8') as json_file:\n",
    "    dict_exiobase_environmental_extensions_sum_rows: dict = json.load(json_file)\n",
    "with open('./list_exiobase_environmental_extensions_drop_rows.json', mode = 'r', encoding = 'utf-8') as json_file:\n",
    "    list_exiobase_environmental_extensions_drop_rows: list = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_environmental_extensions(\n",
    "    F_IO_original_extensions: pd.DataFrame,\n",
    "    F_IO_new_extensions: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        F_IO_original_extensions (pd.DataFrame): _description_\n",
    "        F_IO_new_extensions (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # drop rows\n",
    "    F_IO_new_extensions.drop(labels = list_exiobase_environmental_extensions_drop_rows, inplace=True, errors = 'ignore')\n",
    "    # sum rows into new rows and drop old rows\n",
    "    F_IO_new_extensions = sum_rows_based_on_row_names_conditions(\n",
    "        df = F_IO_new_extensions,\n",
    "        dict_row_names_conditions = dict_exiobase_environmental_extensions_sum_rows\n",
    "    )\n",
    "\n",
    "    F_IO_complete_extensions: pd.DataFrame = pd.concat([F_IO_original_extensions, F_IO_new_extensions])\n",
    "\n",
    "    return F_IO_complete_extensions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylcaio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af11b17298303d3420ac04a2d81997bb73d15b4df2e0afffe06f0aa93756cff5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
