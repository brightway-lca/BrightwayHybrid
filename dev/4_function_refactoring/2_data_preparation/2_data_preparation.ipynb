{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i/o\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import pickle\n",
    "import json\n",
    "# configuration\n",
    "import yaml\n",
    "# lca\n",
    "#import pymrio\n",
    "#import brightway2 as bw\n",
    "# type hints\n",
    "#from pymrio import IOSystem\n",
    "# data science\n",
    "import pandas as pd\n",
    "# deep copy\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2. file paths\n",
    "## 0.2.1. config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../config.yaml', 'r') as filestream:\n",
    "    config = yaml.load(filestream, Loader = yaml.FullLoader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3. file paths\n",
    "## 0.3.1. directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(path_dir_data := Path(Path.home(), config['path_dir_data']))\n",
    "print(path_dir_data_raw := Path(path_dir_data, config['path_dir_data_raw']))\n",
    "print(path_dir_data_processed := Path(path_dir_data, config['path_dir_data_processed']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3.2. files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(path_file_exiobase_pymrio_io_system := Path(path_dir_data_processed, config['pymrio_class_instance']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. refactoring\n",
    "\n",
    "## 1.1. `completing_extensions()`\n",
    "### 1.1.1. legacy\n",
    "\n",
    "[`pylcaio.py > lines 2498-2563`](https://github.com/OASES-project/pylcaio/blob/fa5378df55c314c2f021f4f10b675bb822b3d912/src/pylcaio.py#L2498https://github.com/OASES-project/pylcaio/blob/fa5378df55c314c2f021f4f10b675bb822b3d912/src/pylcaio.py#L2498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completing_extensions(OG_extensions, new_extensions):\n",
    "    \"\"\"Function to modify the names of the extensions of the original exiobase to match the ones resulting from the\n",
    "    matching with USEEIO. Also concatenates both original and new extensions at the end, resulting in the extended\n",
    "    exiensions.\"\"\"\n",
    "    # just remove Energy Carrier Net flows and not defined waste flows\n",
    "    OG_extensions.drop([i for i in OG_extensions.index if 'Energy Carrier Net' in i],inplace=True)\n",
    "    OG_extensions.drop(['Emissions nec - waste - undef'],inplace=True)\n",
    "    # simple sum of all values for old names pollutants, e.g., 'CH4 - non combustion - Cement production - air' => 'CH4 - air'\n",
    "    easy_match = ['CH4','N2O','SOx','NH3','HCB','NMVOC','PM10','PM2.5','TSP','Cd','Hg','Pb','Zn','PAH']\n",
    "    for pollutant in easy_match:\n",
    "        list_old_names = [i for i in OG_extensions.index if pollutant in i]\n",
    "        OG_extensions.loc[pollutant+' - air'] = OG_extensions.loc[list_old_names].sum()\n",
    "        OG_extensions.drop(list_old_names, inplace=True)\n",
    "    # hardcoded stuff\n",
    "    OG_extensions.loc['Benzo(a)pyrene - air'] = OG_extensions.loc[['Benzo(a)pyrene - combustion - air','B(a)P - non combustion - Primary aluminium production - air','B(a)P - non combustion - Production of coke oven coke - air','B(a)P - non combustion - Production of gascoke - air']].sum()\n",
    "    OG_extensions.drop(['Benzo(a)pyrene - combustion - air','B(a)P - non combustion - Primary aluminium production - air','B(a)P - non combustion - Production of coke oven coke - air','B(a)P - non combustion - Production of gascoke - air'],inplace=True)\n",
    "    OG_extensions.loc['Benzo(b)fluoranthene - air'] = OG_extensions.loc[['Benzo(b)fluoranthene - combustion - air','B(b)F - non combustion - Primary aluminium production - air','B(b)F - non combustion - Production of coke oven coke - air','B(b)F - non combustion - Production of gascoke - air']].sum()\n",
    "    OG_extensions.drop(['Benzo(b)fluoranthene - combustion - air','B(b)F - non combustion - Primary aluminium production - air','B(b)F - non combustion - Production of coke oven coke - air','B(b)F - non combustion - Production of gascoke - air'],inplace=True)\n",
    "    OG_extensions.loc['Benzo(k)fluoranthene - air'] = OG_extensions.loc[['Benzo(k)fluoranthene - combustion - air','B(k)F - non combustion - Primary aluminium production - air','B(k)F - non combustion - Production of coke oven coke - air','B(k)F - non combustion - Production of gascoke - air']].sum()\n",
    "    OG_extensions.drop(['Benzo(k)fluoranthene - combustion - air','B(k)F - non combustion - Primary aluminium production - air','B(k)F - non combustion - Production of coke oven coke - air','B(k)F - non combustion - Production of gascoke - air'],inplace=True)\n",
    "    OG_extensions.loc['CO2 - biogenic - air'] = OG_extensions.loc['CO2 - waste - biogenic - air']\n",
    "    OG_extensions.drop(['CO2 - waste - biogenic - air'],inplace=True)\n",
    "    OG_extensions.loc['Pxx - soil'] = OG_extensions.loc[['Pxx - agriculture - soil','P - agriculture - soil']].sum()\n",
    "    OG_extensions.drop(['Pxx - agriculture - soil','P - agriculture - soil'],inplace=True)\n",
    "    old_CO2_flows = [i for i in OG_extensions.index if 'CO2' in i and 'biogenic' not in i]\n",
    "    OG_extensions.loc['CO2 - air'] = OG_extensions.loc[old_CO2_flows].sum() # adds new row 'CO2 - air' and sums all CO2 flows\n",
    "    OG_extensions.drop(old_CO2_flows,inplace=True)\n",
    "    old_CO_flows = [i for i in OG_extensions.index if 'CO' in i and '2' not in i]\n",
    "    OG_extensions.loc['CO - air'] = OG_extensions.loc[old_CO_flows].sum()\n",
    "    OG_extensions.drop(old_CO_flows,inplace=True)\n",
    "    old_NOx_flows = [i for i in OG_extensions.index if 'NOx' in i or 'NOX' in i]\n",
    "    OG_extensions.loc['NOx - air'] = OG_extensions.loc[old_NOx_flows].sum()\n",
    "    OG_extensions.drop(old_NOx_flows,inplace=True)\n",
    "    old_indeno_flows = [i for i in OG_extensions.index if 'Indeno' in i]\n",
    "    OG_extensions.loc['Indeno(1,2,3-cd)pyrene - air'] = OG_extensions.loc[old_indeno_flows].sum()\n",
    "    OG_extensions.drop(old_indeno_flows,inplace=True)\n",
    "    old_PCB_flows = [i for i in OG_extensions.index if 'PCB' in i]\n",
    "    OG_extensions.loc['PCBs - air'] = OG_extensions.loc[old_PCB_flows].sum()\n",
    "    OG_extensions.drop(old_PCB_flows,inplace=True)\n",
    "    old_PCDD_flows = [i for i in OG_extensions.index if 'PCDD' in i]\n",
    "    OG_extensions.loc['PCDD_F - air'] = OG_extensions.loc[old_PCDD_flows].sum()\n",
    "    OG_extensions.drop(old_PCDD_flows,inplace=True)\n",
    "    old_As_flows = [i for i in OG_extensions.index if 'As -' in i]\n",
    "    OG_extensions.loc['As - air'] = OG_extensions.loc[old_As_flows].sum()\n",
    "    OG_extensions.drop(old_As_flows,inplace=True)\n",
    "    old_Ni_flows = [i for i in OG_extensions.index if 'Ni -' in i]\n",
    "    OG_extensions.loc['Ni - air'] = OG_extensions.loc[old_Ni_flows].sum()\n",
    "    OG_extensions.drop(old_Ni_flows,inplace=True)\n",
    "    old_Cr_flows = [i for i in OG_extensions.index if 'Cr -' in i]\n",
    "    OG_extensions.loc['Cr - air'] = OG_extensions.loc[old_Cr_flows].sum()\n",
    "    OG_extensions.drop(old_Cr_flows,inplace=True)\n",
    "    old_Cu_flows = [i for i in OG_extensions.index if 'Cu -' in i]\n",
    "    OG_extensions.loc['Cu - air'] = OG_extensions.loc[old_Cu_flows].sum()\n",
    "    OG_extensions.drop(old_Cu_flows,inplace=True)\n",
    "    old_Se_flows = [i for i in OG_extensions.index if 'Se -' in i]\n",
    "    OG_extensions.loc['Se - air'] = OG_extensions.loc[old_Se_flows].sum()\n",
    "    OG_extensions.drop(old_Se_flows,inplace=True)\n",
    "    old_N_flows = [i for i in OG_extensions.index if 'N -' in i]\n",
    "    OG_extensions.loc['N - water'] = OG_extensions.loc[old_N_flows].sum()\n",
    "    OG_extensions.drop(old_N_flows,inplace=True)\n",
    "    old_P_flows = [i for i in OG_extensions.index if 'P -' in i and 'water' in i]\n",
    "    OG_extensions.loc['P - water'] = OG_extensions.loc[old_P_flows].sum()\n",
    "    OG_extensions.drop(old_P_flows,inplace=True)\n",
    "    # after all this hardwork, concatenate with extensions\n",
    "    extended_extensions = pd.concat([OG_extensions,new_extensions])\n",
    "    return extended_extensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exiobase: IOSystem = pd.read_pickle(path_file_exiobase_pymrio_io_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Taxes less subsidies on products purchased: Total',\n",
       "       'Other net taxes on production',\n",
       "       'Compensation of employees; wages, salaries, & employers' social contributions: Low-skilled',\n",
       "       'Compensation of employees; wages, salaries, & employers' social contributions: Medium-skilled',\n",
       "       'Compensation of employees; wages, salaries, & employers' social contributions: High-skilled',\n",
       "       'Operating surplus: Consumption of fixed capital',\n",
       "       'Operating surplus: Rents on land',\n",
       "       'Operating surplus: Royalties on resources',\n",
       "       'Operating surplus: Remaining net operating surplus',\n",
       "       'Employment: Low-skilled male',\n",
       "       ...\n",
       "       'Water Withdrawal Blue - Domestic - domestic Water Withdrawal Blue',\n",
       "       'Energy Carrier Net Total', 'Energy Carrier Net NENE',\n",
       "       'Energy Carrier Net NTRA', 'Energy Carrier Net TAVI',\n",
       "       'Energy Carrier Net TMAR', 'Energy Carrier Net TOTH',\n",
       "       'Energy Carrier Net TRAI', 'Energy Carrier Net TROA',\n",
       "       'Energy Carrier Net LOSS'],\n",
       "      dtype='object', name='stressor', length=1113)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exiobase.satellite.F.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dict_exiobase_environmental_extensions_sum_rows.json', mode = 'r', encoding = 'utf-8') as json_file:\n",
    "    dict_exiobase_environmental_extensions_sum_rows: dict = json.load(json_file)\n",
    "with open('./list_exiobase_environmental_extensions_drop_rows.json', mode = 'r', encoding = 'utf-8') as json_file:\n",
    "    list_exiobase_environmental_extensions_drop_rows: list = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rows_based_on_row_names_conditions(\n",
    "    df_input: pd.DataFrame,\n",
    "    dict_row_names_conditions: dict,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes an input dataframe with an index column of row names and sums the rows specified in the rows dictionary.\n",
    "    The rows dictionary has keys that are the new row names and values that are boolean conditions on the row names of the rows to be summed.\n",
    "    Rows that are summed over are dropped from the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df_input (pd.DataFrame): input dataframe with an index column of row names\n",
    "        dict_row_names_conditions (dict): a dictionary where rows.keys() are the new row names and rows.values() are conditions on the row names of the rows to be summed\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: output dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    for new_row_name, old_rows_names_conditions in dict_row_names_conditions.items():\n",
    "        old_rows_names: list = [*df_input.query(old_rows_names_conditions).index]\n",
    "        df_input.loc[new_row_name] = df.loc[old_rows_names].sum()\n",
    "        df_output: pd.DataFrame = df_input.drop(labels = old_rows_names, errors = 'ignore')\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_environmental_extensions(\n",
    "    F_IO_original_extensions: pd.DataFrame,\n",
    "    F_IO_new_extensions: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        F_IO_original_extensions (pd.DataFrame): _description_\n",
    "        F_IO_new_extensions (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    df = F_IO_original_extensions.copy()\n",
    "\n",
    "    df = df.drop(labels = list_exiobase_environmental_extensions_drop_rows, errors = 'ignore')\n",
    "    df = sum_rows_based_on_row_names_conditions(\n",
    "        df_input = df,\n",
    "        dict_row_names_conditions = dict_exiobase_environmental_extensions_sum_rows\n",
    "    )\n",
    "\n",
    "    df_output: pd.DataFrame = pd.concat([df, F_IO_new_extensions])\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. `get_inflation()`\n",
    "### 1.2.1. legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inflation(reference_year):\n",
    "    \"\"\" Returns the inflation rate between the year 2005 (base year for ecoinvent prices) and the reference year of\n",
    "    the used IO database, from https://www.inflationtool.com/euro/2005-to-present-value\"\"\"\n",
    "\n",
    "    if reference_year == 1995:\n",
    "        inflation = 0.83\n",
    "    elif reference_year == 1996:\n",
    "        inflation = 0.84\n",
    "    elif reference_year == 1997:\n",
    "        inflation = 0.86\n",
    "    elif reference_year == 1998:\n",
    "        inflation = 0.87\n",
    "    elif reference_year == 1999:\n",
    "        inflation = 0.88\n",
    "    elif reference_year == 2000:\n",
    "        inflation = 0.9\n",
    "    elif reference_year == 2001:\n",
    "        inflation = 0.92\n",
    "    elif reference_year == 2002:\n",
    "        inflation = 0.94\n",
    "    elif reference_year == 2003:\n",
    "        inflation = 0.96\n",
    "    elif reference_year == 2004:\n",
    "        inflation = 0.98\n",
    "    elif reference_year == 2005:\n",
    "        inflation = 1\n",
    "    elif reference_year == 2006:\n",
    "        inflation = 1.02\n",
    "    elif reference_year == 2007:\n",
    "        inflation = 1.04\n",
    "    elif reference_year == 2008:\n",
    "        inflation = 1.08\n",
    "    elif reference_year == 2009:\n",
    "        inflation = 1.08\n",
    "    elif reference_year == 2010:\n",
    "        inflation = 1.10\n",
    "    elif reference_year == 2011:\n",
    "        inflation = 1.13\n",
    "    elif reference_year == 2012:\n",
    "        inflation = 1.16\n",
    "    elif reference_year == 2013:\n",
    "        inflation = 1.18\n",
    "    elif reference_year == 2014:\n",
    "        inflation = 1.19\n",
    "    elif reference_year == 2015:\n",
    "        inflation = 1.19\n",
    "    elif reference_year == 2016:\n",
    "        inflation = 1.19\n",
    "    elif reference_year == 2017:\n",
    "        inflation = 1.21\n",
    "    elif reference_year == 2018:\n",
    "        inflation = 1.22\n",
    "    elif reference_year == 2019:\n",
    "        inflation = 1.24\n",
    "    elif reference_year == 2020:\n",
    "        inflation = 1.26\n",
    "    elif reference_year == 2021:\n",
    "        inflation = 1.25\n",
    "    # no data available for 2022, same data as 2021 by default\n",
    "    elif reference_year == 2022:\n",
    "        inflation = 1.25\n",
    "    else:\n",
    "        inflation = 1\n",
    "\n",
    "    return inflation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbnomics\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consumer_price_index_data(\n",
    "    baseline_year: int,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Returns a dataframe containing a time series of the Inflation Multiplier (as determined by the Consumer Price Index) normalized against a baseline year.\n",
    "    Date range covered is [1996, current year]. Geographic coverage is the European Economic Area (EEA18-1995, EEA28-2004, EEA30-2007, EEA31-2013, EEA30-2020).\n",
    "    Data source: https://db.nomics.world/Eurostat/prc_hicp_aind/A.INX_A_AVG.CP00.EEA\n",
    "\n",
    "    Args:\n",
    "        baseline_year (int): baseline year for normalization\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: output dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_inflation: pd.DataFrame = dbnomics.fetch_series('Eurostat/prc_hicp_aind/A.INX_A_AVG.CP00.EEA')[['period', 'value']]\n",
    "    df_inflation['value'] = df_inflation['value'] / df_inflation.loc[df_inflation['period'] == datetime.strptime('2005', '%Y'), 'value'].iloc[0]\n",
    "\n",
    "    while df_inflation['period'].iloc[-1].year < datetime.now().year:\n",
    "\n",
    "        next_year = df_inflation['period'].iloc[-1] + pd.DateOffset(years=1)\n",
    "        last_available_value = df_inflation['value'].iloc[-1]\n",
    "\n",
    "        df_inflation = pd.concat(\n",
    "            [df_inflation, pd.DataFrame({'period': [next_year], 'value': [last_available_value]})],\n",
    "            axis = 0,\n",
    "            ignore_index = False\n",
    "        )\n",
    "\n",
    "    return df_inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_consumer_price_index_data(2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>0.849027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>0.863653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>0.874894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>0.885289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>0.902212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>0.922156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>0.941255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>0.959749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.978847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>1.022120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>1.045812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>1.084129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>1.095129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1.117974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1.152424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1.182642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1.200411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1.207301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1.208751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.212257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1.233047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.256497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1.275112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1.284661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1.322011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1.322011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.322011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period     value\n",
       "0  1996-01-01  0.849027\n",
       "1  1997-01-01  0.863653\n",
       "2  1998-01-01  0.874894\n",
       "3  1999-01-01  0.885289\n",
       "4  2000-01-01  0.902212\n",
       "5  2001-01-01  0.922156\n",
       "6  2002-01-01  0.941255\n",
       "7  2003-01-01  0.959749\n",
       "8  2004-01-01  0.978847\n",
       "9  2005-01-01  1.000000\n",
       "10 2006-01-01  1.022120\n",
       "11 2007-01-01  1.045812\n",
       "12 2008-01-01  1.084129\n",
       "13 2009-01-01  1.095129\n",
       "14 2010-01-01  1.117974\n",
       "15 2011-01-01  1.152424\n",
       "16 2012-01-01  1.182642\n",
       "17 2013-01-01  1.200411\n",
       "18 2014-01-01  1.207301\n",
       "19 2015-01-01  1.208751\n",
       "20 2016-01-01  1.212257\n",
       "21 2017-01-01  1.233047\n",
       "22 2018-01-01  1.256497\n",
       "23 2019-01-01  1.275112\n",
       "24 2020-01-01  1.284661\n",
       "25 2021-01-01  1.322011\n",
       "0  2022-01-01  1.322011\n",
       "0  2023-01-01  1.322011"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c47573e6b76e4e3b75c409f99dfa4e531246fb1edc220bf519a288d15e464ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
