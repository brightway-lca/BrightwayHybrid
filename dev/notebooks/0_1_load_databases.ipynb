{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 follow setup instructions\n",
    "\n",
    "ℹ️ use [`pylcaio.yml`](https://github.com/michaelweinold/config_conda/blob/main/pylcaio.yml) to set up working conda environment.\n",
    "\n",
    "⚠️ beware the estimated hardware requirements:\n",
    "\n",
    "1. \\>16GB RAM\n",
    "\n",
    "⚠️ beware the following error messages:\n",
    "\n",
    "1. [`AttributeError: 'IOSystem' object has no attribute 'Z' and then KeyError: 'PRO'`](https://github.com/michaelweinold/pylcaio_integration_with_brightway/issues/4) \\\n",
    "Caused by repeated execution of the `database_loader.combine_ecoinvent_exiobase()` and/or `lcaio_object.hybridize()` functions.\n",
    "\n",
    "⚠️ `brightway` import [currently breaks `%autoreload` magic](https://github.com/brightway-lca/brightway2/issues/49)\n",
    "\n",
    "### 0.1. imports\n",
    "#### 0.1.1. regular imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i/o\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import pickle\n",
    "# configuration\n",
    "import yaml\n",
    "# lca\n",
    "import ecospold2matrix as e2m\n",
    "import pymrio\n",
    "#import brightway2 as bw\n",
    "# type hints\n",
    "from ecospold2matrix import ecospold2matrix\n",
    "from pymrio import IOSystem\n",
    "# data science\n",
    "import pandas as pd\n",
    "# deep copy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1.2. local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import (\n",
    "    read_ecoinvent_pickle,\n",
    "    read_exiobase_pickle\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1.3. load configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as filestream:\n",
    "    config = yaml.load(filestream, Loader = yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1.4. load `pylcaio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(Path.home(), config['pylcaio'])) # required for local import of pylcaio\n",
    "import pylcaio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. file paths\n",
    "#### 0.2.1. directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weinold\n",
      "/home/weinold/data_pylcaio_input\n",
      "/home/weinold/data\n",
      "/home/weinold/data/data_pylcaio\n",
      "/home/weinold/data/data_pymrio\n",
      "/home/weinold/data/data_e2m\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "# home directory\n",
    "print(path_dir_home := Path.home())\n",
    "# input directory\n",
    "print(path_dir_databases := os.path.join(path_dir_home, config['path_dir_databases']))\n",
    "# output directories\n",
    "print(path_dir_data := os.path.join(path_dir_home, config['path_dir_data']))\n",
    "print(path_dir_pylcaio := os.path.join(path_dir_home, path_dir_data, config['path_dir_pylcaio']))\n",
    "print(path_dir_pymrio := os.path.join(path_dir_home, path_dir_data, config['path_dir_pymrio']))\n",
    "print(path_dir_e2m := os.path.join(path_dir_home, path_dir_data, config['path_dir_e2m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2.2. files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weinold/data_pylcaio_input/exiobase_monetary_pxp/IOT_2012_pxp.zip\n",
      "/home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff\n",
      "/home/weinold/data/data_pylcaio/pylcaio_database_loader_class_instance.pkl\n",
      "/home/weinold/data/data_pylcaio/pylcaio_class_instance_before_hybrid.pkl\n",
      "/home/weinold/data/data_pylcaio/pylcaio_class_instance_after_hybrid.pkl\n",
      "/home/weinold/data/data_pymrio/pymrio_class_instance.pkl\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "# databases\n",
    "print(path_exiobase := os.path.join(path_dir_home, path_dir_databases, config['exiobase']))\n",
    "print(path_dir_ecoinvent := os.path.join(path_dir_home, path_dir_databases, config['ecoinvent']))\n",
    "# pylcaio output\n",
    "print(pylcaio_database_loader_class_instance := os.path.join(path_dir_pylcaio, config['pylcaio_database_loader_class_instance']))\n",
    "print(pylcaio_class_instance_before_hybrid := os.path.join(path_dir_pylcaio, config['pylcaio_class_instance_before_hybrid']))\n",
    "print(pylcaio_class_instance_after_hybrid := os.path.join(path_dir_pylcaio, config['pylcaio_class_instance_after_hybrid']))\n",
    "# pymrio output\n",
    "print(pymrio_class_instance := os.path.join(path_dir_pymrio, config['pymrio_class_instance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: missing operand\n",
      "Try 'mkdir --help' for more information.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p $path_dir_data\n",
    "!mkdir -p $path_dir_e2m\n",
    "!mkdir -p $path_dir_ecoinvent && cp -ru /srv/data/ecoinvent-3.5-cutoff/* $path_dir_ecoinvent\n",
    "#!mkdir -p $path_exiobase && cp -ru /srv/data/exiobase_monetary_pxp/* $path_exiobase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. read databases and create dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_disk: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 read Exiobase database and save pickle to disk\n",
    "\n",
    "❔ creates pymrio.IOSystem class instance (collection of pd.DataFrames etc.) \\\n",
    "⏳ ~1min if `load_from_disk == False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_disk == True:\n",
    "    exiobase: pymrio.core.mriosystem.IOSystem = read_exiobase_pickle(pymrio_class_instance)\n",
    "else:\n",
    "    exiobase: pymrio.IOSystem = pymrio.parse_exiobase3(path_exiobase)\n",
    "    with open(pymrio_class_instance, 'wb') as file_handle:    \n",
    "        pickle.dump(obj = exiobase, file = file_handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 read ecoinvent\n",
    "\n",
    "❔ creates e2m.Ecospold2Matrix class instance and writes dataframe to defined output directory in `pickle` format. \\\n",
    "⏳ ~12min if `load_from_disk == False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoinvent_3_5_cutoff\n",
      "ecoinvent_3_5_cutoffPandas_symmNorm.gz.pickle\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'path_dir_e2m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(name_project_e2m \u001b[38;5;241m:=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecoinvent_3_5_cutoff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(filename_project_e2m \u001b[38;5;241m:=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(name_project_e2m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPandas_symmNorm.gz.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(path_dir_e2m_logs \u001b[38;5;241m:=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mpath_dir_e2m\u001b[49m, name_project_e2m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_log\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(path_file_e2m_pickle \u001b[38;5;241m:=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_dir_e2m, filename_project_e2m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(pattern_e2m_characterization_db \u001b[38;5;241m:=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_dir_e2m' is not defined"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "print(name_project_e2m := 'ecoinvent_3_5_cutoff')\n",
    "print(filename_project_e2m := os.path.join(name_project_e2m + 'Pandas_symmNorm.gz.pickle'))\n",
    "print(path_dir_e2m_logs := os.path.join(path_dir_e2m, name_project_e2m, '_log'))\n",
    "print(path_file_e2m_pickle := os.path.join(path_dir_e2m, filename_project_e2m))\n",
    "print(pattern_e2m_characterization_db := '*.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_e2m_files(list_string: list) -> None:\n",
    "    for i in list_string:\n",
    "        !rm -rf $i\n",
    "    pass\n",
    "\n",
    "\n",
    "def copy_ecoinvent_from_shared_to_local(path: path_dir_ecoinvent) -> None:\n",
    "    !mkdir -p $path_dir_ecoinvent && cp -ru /srv/data/ecoinvent-3.5-cutoff/* $path_dir_ecoinvent\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 12:24:43,782 - ecoinvent_3_5_cutoff - INFO - Ecospold2Matrix Processing\n",
      "INFO:ecoinvent_3_5_cutoff:Ecospold2Matrix Processing\n",
      "2022-09-10 12:24:43,784 - ecoinvent_3_5_cutoff - INFO - Current git commit: 2b78f39ac419e16a6721aa27a0bdb8204e1f0f3a\n",
      "INFO:ecoinvent_3_5_cutoff:Current git commit: 2b78f39ac419e16a6721aa27a0bdb8204e1f0f3a\n",
      "2022-09-10 12:24:43,785 - ecoinvent_3_5_cutoff - INFO - Project name: ecoinvent_3_5_cutoff\n",
      "INFO:ecoinvent_3_5_cutoff:Project name: ecoinvent_3_5_cutoff\n",
      "2022-09-10 12:24:43,785 - ecoinvent_3_5_cutoff - INFO - Unit process and Master data directory: /home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff\n",
      "INFO:ecoinvent_3_5_cutoff:Unit process and Master data directory: /home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff\n",
      "2022-09-10 12:24:43,786 - ecoinvent_3_5_cutoff - INFO - Data saved in: /home/weinold/data/data_e2m\n",
      "INFO:ecoinvent_3_5_cutoff:Data saved in: /home/weinold/data/data_e2m\n",
      "2022-09-10 12:24:43,787 - ecoinvent_3_5_cutoff - INFO - Replace Not-a-Number instances with 0.0 in all matrices\n",
      "INFO:ecoinvent_3_5_cutoff:Replace Not-a-Number instances with 0.0 in all matrices\n",
      "2022-09-10 12:24:43,787 - ecoinvent_3_5_cutoff - INFO - Pickle intermediate results to files\n",
      "INFO:ecoinvent_3_5_cutoff:Pickle intermediate results to files\n",
      "2022-09-10 12:24:43,788 - ecoinvent_3_5_cutoff - INFO - Order processes based on: ISIC, activityName\n",
      "INFO:ecoinvent_3_5_cutoff:Order processes based on: ISIC, activityName\n",
      "2022-09-10 12:24:43,789 - ecoinvent_3_5_cutoff - INFO - Order elementary exchanges based on: comp, name, subcomp\n",
      "INFO:ecoinvent_3_5_cutoff:Order elementary exchanges based on: comp, name, subcomp\n",
      "rm: cannot remove 'ecoinvent_3_5_cutoff_characterisation.db': No such file or directory\n",
      "2022-09-10 12:24:43,802 - ecoinvent_3_5_cutoff - WARNING - obs2char_subcomps constraints temporarily relaxed because not full recipe parsed\n",
      "WARNING:ecoinvent_3_5_cutoff:obs2char_subcomps constraints temporarily relaxed because not full recipe parsed\n",
      "2022-09-10 12:24:43,886 - ecoinvent_3_5_cutoff - INFO - Products extracted from IntermediateExchanges.xml with SHA-1 of b2c87a5bf5982a60515a6e1160e43c620a218369\n",
      "INFO:ecoinvent_3_5_cutoff:Products extracted from IntermediateExchanges.xml with SHA-1 of b2c87a5bf5982a60515a6e1160e43c620a218369\n",
      "2022-09-10 12:24:52,722 - ecoinvent_3_5_cutoff - WARNING - Removed 1148 duplicate rows from activity_list, see duplicate_activity_list.csv.\n",
      "WARNING:ecoinvent_3_5_cutoff:Removed 1148 duplicate rows from activity_list, see duplicate_activity_list.csv.\n",
      "2022-09-10 12:24:52,776 - ecoinvent_3_5_cutoff - INFO - Activities extracted from ActivityIndex.xml with SHA-1 of 3ac94e9826a9a031ff2e0bfbdceeecaeb72a9117\n",
      "INFO:ecoinvent_3_5_cutoff:Activities extracted from ActivityIndex.xml with SHA-1 of 3ac94e9826a9a031ff2e0bfbdceeecaeb72a9117\n",
      "2022-09-10 12:24:52,797 - ecoinvent_3_5_cutoff - INFO - Processing 16022 files in /home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff/datasets\n",
      "INFO:ecoinvent_3_5_cutoff:Processing 16022 files in /home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff/datasets\n",
      "2022-09-10 12:25:49,784 - ecoinvent_3_5_cutoff - INFO - Flows saved in /home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff/flows.pickle with SHA-1 of cc46592ef24fcf45f7acc935b4fc76a8acbd062c\n",
      "INFO:ecoinvent_3_5_cutoff:Flows saved in /home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff/flows.pickle with SHA-1 of cc46592ef24fcf45f7acc935b4fc76a8acbd062c\n",
      "2022-09-10 12:25:49,862 - ecoinvent_3_5_cutoff - INFO - Processing 16022 files - this may take a while ...\n",
      "INFO:ecoinvent_3_5_cutoff:Processing 16022 files - this may take a while ...\n",
      "2022-09-10 12:26:49,021 - ecoinvent_3_5_cutoff - INFO - Elementary flows extracted from ElementaryExchanges.xml with SHA-1 of 0caa74a71870c1432557a91516a6da63d319b594\n",
      "INFO:ecoinvent_3_5_cutoff:Elementary flows extracted from ElementaryExchanges.xml with SHA-1 of 0caa74a71870c1432557a91516a6da63d319b594\n",
      "2022-09-10 12:26:49,064 - ecoinvent_3_5_cutoff - INFO - Labels saved in /home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff/rawlabels.pickle with SHA-1 of 8bc41809cd42bb043ce5c69ae0ab324f16a25bc8\n",
      "INFO:ecoinvent_3_5_cutoff:Labels saved in /home/weinold/data_pylcaio_input/ecoinvent-3.5-cutoff/rawlabels.pickle with SHA-1 of 8bc41809cd42bb043ce5c69ae0ab324f16a25bc8\n",
      "2022-09-10 12:26:49,074 - ecoinvent_3_5_cutoff - INFO - OK.   No untraceable flows.\n",
      "INFO:ecoinvent_3_5_cutoff:OK.   No untraceable flows.\n",
      "2022-09-10 12:26:49,350 - ecoinvent_3_5_cutoff - INFO - OK. Source activities seem in order. Each product traceable to an activity that actually does produce or distribute this product.\n",
      "INFO:ecoinvent_3_5_cutoff:OK. Source activities seem in order. Each product traceable to an activity that actually does produce or distribute this product.\n",
      "2022-09-10 12:26:49,675 - ecoinvent_3_5_cutoff - INFO - Starting to assemble the matrices\n",
      "INFO:ecoinvent_3_5_cutoff:Starting to assemble the matrices\n",
      "2022-09-10 12:26:51,093 - ecoinvent_3_5_cutoff - INFO - fillna\n",
      "INFO:ecoinvent_3_5_cutoff:fillna\n",
      "2022-09-10 12:26:57,606 - ecoinvent_3_5_cutoff - INFO - Starting normalizing matrices\n",
      "INFO:ecoinvent_3_5_cutoff:Starting normalizing matrices\n",
      "2022-09-10 12:27:07,512 - ecoinvent_3_5_cutoff - INFO - Starting to export to file\n",
      "INFO:ecoinvent_3_5_cutoff:Starting to export to file\n",
      "2022-09-10 12:27:07,516 - ecoinvent_3_5_cutoff - INFO - about to write to file\n",
      "INFO:ecoinvent_3_5_cutoff:about to write to file\n",
      "2022-09-10 12:30:01,319 - ecoinvent_3_5_cutoff - INFO - Final, symmetric, normalized matrices saved in /home/weinold/data/data_e2m/ecoinvent_3_5_cutoffPandas_symmNorm.gz.pickle with SHA-1 of de8f081afaba61b08cbacc66cfc270bb22087881\n",
      "INFO:ecoinvent_3_5_cutoff:Final, symmetric, normalized matrices saved in /home/weinold/data/data_e2m/ecoinvent_3_5_cutoffPandas_symmNorm.gz.pickle with SHA-1 of de8f081afaba61b08cbacc66cfc270bb22087881\n",
      "2022-09-10 12:32:55,713 - ecoinvent_3_5_cutoff - INFO - Final, symmetric, scaled-up flow matrices saved in /home/weinold/data/data_e2m/ecoinvent_3_5_cutoffPandas_symmScale.gz.pickle with SHA-1 of e4d521b73b0ae065bc439c6c4c0946a746234278\n",
      "INFO:ecoinvent_3_5_cutoff:Final, symmetric, scaled-up flow matrices saved in /home/weinold/data/data_e2m/ecoinvent_3_5_cutoffPandas_symmScale.gz.pickle with SHA-1 of e4d521b73b0ae065bc439c6c4c0946a746234278\n",
      "2022-09-10 12:32:55,714 - ecoinvent_3_5_cutoff - INFO - Done running ecospold2matrix.ecospold_to_Leontief\n",
      "INFO:ecoinvent_3_5_cutoff:Done running ecospold2matrix.ecospold_to_Leontief\n"
     ]
    }
   ],
   "source": [
    "if load_from_disk == True:\n",
    "    ecoinvent: dict = read_ecoinvent_pickle(path_file_e2m_pickle)\n",
    "else:\n",
    "    delete_e2m_files(\n",
    "        [\n",
    "            path_dir_e2m,\n",
    "            path_dir_e2m_logs,\n",
    "            path_dir_ecoinvent,\n",
    "            pattern_e2m_characterization_db\n",
    "        ]\n",
    "    )\n",
    "    copy_ecoinvent_from_shared_to_local(path_dir_ecoinvent)\n",
    "    parser = e2m.Ecospold2Matrix(\n",
    "        sys_dir = path_dir_ecoinvent,\n",
    "        project_name = name_project_e2m,\n",
    "        out_dir = path_dir_e2m,\n",
    "        #characterisation_file = path_e2m_char_file,\n",
    "        positive_waste = False,\n",
    "        nan2null = True)\n",
    "    parser.ecospold_to_Leontief(\n",
    "        fileformats = 'Pandas',\n",
    "        with_absolute_flows=True)\n",
    "    ecoinvent: dict = read_ecoinvent_pickle(path_file_e2m_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. main `pylcaio` functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_loader: pylcaio.DatabaseLoader  = pylcaio.DatabaseLoader(\n",
    "    lca_database_processed = ecoinvent,\n",
    "    io_database_processed = exiobase,\n",
    "    lca_database_name_and_version = 'ecoinvent3.5',\n",
    "    io_database_name_and_version = 'exiobase3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pylcaio_database_loader_class_instance, 'wb') as file_handle:\n",
    "    pickle.dump(obj = database_loader, file = file_handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No path for the capital folder was provided. Capitals will not be endogenized\n"
     ]
    }
   ],
   "source": [
    "lcaio_object: pylcaio.LCAIO = database_loader.combine_ecoinvent_exiobase(\n",
    "    complete_extensions = False,\n",
    "    impact_world = False,\n",
    "    regionalized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pylcaio_class_instance_before_hybrid, 'wb') as file_handle:\n",
    "    pickle.dump(obj = lcaio_object, file = file_handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indentifying Rest of World regions...\n",
      "Updating electricity prices...\n",
      "Calculating productions volumes...\n",
      "Adjusting low production volume processes...\n",
      "Extending inventory...\n",
      "Building H matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weinold/github/pylcaio_integration_with_brightway/src/pylcaio.py:877: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.H = self.H.append([self.H] * (self.number_of_countries_IO + self.number_of_RoW_IO - 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building geography concordance...\n",
      "Filter H matrix...\n",
      "Build Cut-off matrix...\n",
      "Add processes with 'priceless scaling' to Cut-off matrix...\n"
     ]
    }
   ],
   "source": [
    "lcaio_object.hybridize(\n",
    "    price_neutral_cut_off_matrix = 'STAM',\n",
    "    capitals = False,\n",
    "    priceless_scaling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pylcaio_class_instance_after_hybrid, 'wb') as file_handle:\n",
    "    pickle.dump(obj = lcaio_object, file = file_handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. move files to `/srv/data` for use by everyone else\n",
    "\n",
    "⚠️ this needs `sudo` rights, so best execute in the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pylcaio.LCAIO"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sudo mkdir -p /srv/data/pylcaio_output/pickle/*\n",
    "sudo cp -r /home/weinold/data_pylcaio_output/* /srv/data/pylcaio_output/pickle/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X.1 exiobase download\n",
    "\n",
    "⚠️ only relevant for users with sudo rights\n",
    "\n",
    "to download the monetary product-by-production versions of Exiobase:\n",
    "\n",
    "1. download using pymrio (compare below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymrio.download_exiobase3(\n",
    "    storage_folder='/home/weinold',\n",
    "    system=\"pxp\",\n",
    "    years=[2011]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. move files to /srv/data using `sudo`\n",
    "\n",
    "```\n",
    "sudo mv ~/*pxp.zip /srv/data/exiobase_monetary_pxp\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pylcaio': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f467ae6f28fc2a0e97326396cf55b215b4c09969dfcc2e6c7c36ad6b4a612a7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
