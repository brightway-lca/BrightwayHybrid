{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data science\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# i/o\n",
    "import json\n",
    "# type hints\n",
    "import ast\n",
    "import pkg_resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weinold/github/pylcaio_integration_with_brightway/helper_functions/countries_per_region.json\n",
      "/home/weinold/github/pylcaio_integration_with_brightway/helper_functions/countries.json\n"
     ]
    }
   ],
   "source": [
    "print(path_countries_per_region := '/home/weinold/github/pylcaio_integration_with_brightway/helper_functions/countries_per_region.json')\n",
    "print(path_countries := '/home/weinold/github/pylcaio_integration_with_brightway/helper_functions/countries.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pymrio\n",
    "print(path_home := os.path.join('/home', os.getlogin()))\n",
    "print(path_dir_out := os.path.join(path_home, 'data_pylcaio_output'))\n",
    "print(path_file_out_pymrio_class_instance_pickle := os.path.join(path_dir_out, 'pymrio_class_instance.pkl'))\n",
    "with open(path_file_out_pymrio_class_instance_pickle, 'rb') as file_in:\n",
    "    exiobase = pd.read_pickle(file_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ countries are IO countries, not LCA countries\n",
    "!!! fix this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file = path_countries_per_region, mode = 'r', encoding = 'utf-8') as filestream:\n",
    "    lca_countries_in_io_regions: dict = json.load(fp = filestream)\n",
    "with open(file = path_countries, mode = 'r', encoding = 'utf-8') as filestream:\n",
    "    lca_countries: list = json.load(fp = filestream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. identify rest-of-world regions (RoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_countries_absent_in_io_regions: dict = {\n",
    "    io_region: [country for country in lca_countries if country not in lca_countries_in_io_region]\n",
    "    for (io_region, lca_countries_in_io_region) in lca_countries_in_io_regions.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lca_regions: int = len(lca_countries_in_io_regions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_sectors: list = list(exiobase.get_sectors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "listmatrixxx = []\n",
    "listlisteee = []\n",
    "listdfff = []\n",
    "for i in range(0, len(lca_countries_absent_in_io_regions)):\n",
    "    listmatrixxx.append('matrixxx' + str(i))\n",
    "    listlisteee.append('listeee' + str(i))\n",
    "    listdfff.append('dfff' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_rows(self):\n",
    "    \"\"\" Method to identify the various unique Rest of the World (RoW) regions of the LCA database\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        The updated self.dictRoW in which unique RoW regions are identified in terms of countries they include\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # contains a list of activityNameId's that are 'PRO_f.io_geography[i]=='RoW (=LCA RoW)'\n",
    "    unique_activities_using_row = list(\n",
    "        set( # removes duplicates\n",
    "            self.PRO_f.activityNameId[\n",
    "                [i for i in self.PRO_f.index if self.PRO_f.io_geography[i] == 'RoW']].tolist()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    RoW_activities = defaultdict(list)\n",
    "\n",
    "    # how and WHERE are `geography` and `io_geography` matched?\n",
    "\n",
    "    tupl = [ # list of tuples (activity, geography) that have io_geography==RoW !!!???\n",
    "        i for i in zip( # zip creates tuple\n",
    "            self.PRO_f.activityNameId.loc[ # pandas series with column activityNameId of all those activities that are 'PRO_f.io_geography[i]=='RoW (=LCA RoW)\n",
    "                [\n",
    "                    i for i in self.PRO_f.index\n",
    "                    if self.PRO_f.activityNameId[i] in unique_activities_using_row\n",
    "                ]\n",
    "            ],\n",
    "            self.PRO_f.io_geography.loc[ # WTF, why even do this, if above you only get those activities that already have self.PRO_f.io_geography[i] == 'RoW']\n",
    "                [\n",
    "                    i for i in self.PRO_f.index\n",
    "                    if self.PRO_f.activityNameId[i] in unique_activities_using_row\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # ok, dictionary is filled\n",
    "    for activity, geography in tupl:\n",
    "        RoW_activities[activity].append(geography)\n",
    "\n",
    "\n",
    "    # remove RoW\n",
    "    RoW_activities = {activity: [geography1 for geography1 in geography if geography1 != 'RoW'] for activity, geography in RoW_activities.items()}\n",
    "\n",
    "    # delete from RoW_activities processes which had only RoW as geography and are thus empty now\n",
    "    for key in [i for i in list(RoW_activities.keys()) if RoW_activities[i] == []]:\n",
    "        del RoW_activities[key]\n",
    "        \n",
    "    # put every element to the same level (elements that are lists are transformed to lists of lists)\n",
    "    for values in list(RoW_activities.values()):\n",
    "        for i in range(0, len(values)):\n",
    "            if values[i] in self.countries_per_regions.keys():\n",
    "                values[i] = self.countries_per_regions[values[i]]\n",
    "    # for elements that are lists of lists stemming from the replacement of ['RER'] by [['AT','BE',...]],\n",
    "    # add all of the together in a single list\n",
    "    for keys in RoW_activities.keys():\n",
    "        for item in RoW_activities[keys]:\n",
    "            if isinstance(item, list):\n",
    "                RoW_activities[keys] = sum_elements_list(RoW_activities[keys])\n",
    "    # remove duplicates inside the elements\n",
    "    for keys in list(RoW_activities.keys()):\n",
    "        RoW_activities[keys] = list(set(RoW_activities[keys]))\n",
    "    # need to sort to identify duplicates whose elements would be ordered differently and thus be treated as not\n",
    "    # duplicated\n",
    "    for keys in RoW_activities.keys():\n",
    "        RoW_activities[keys].sort()\n",
    "    # identify the combination of countries that are NOT inside the residual of each process\n",
    "    dictactrow = {}\n",
    "    residual_geo_IO_to_remove = ['WA', 'WE', 'WF', 'WL', 'WM']\n",
    "    for keys in RoW_activities.keys():\n",
    "        dictactrow[keys] = list(set(self.listcountry) - set(RoW_activities[keys]) - set(residual_geo_IO_to_remove))\n",
    "    unique_RoWs = []\n",
    "    for keys in dictactrow.keys():\n",
    "        if dictactrow[keys] not in unique_RoWs:\n",
    "            unique_RoWs.append(dictactrow[keys])\n",
    "    # create name for the values of the different RoW\n",
    "    listname = []\n",
    "    for i in range(0, len(unique_RoWs)):\n",
    "        listname.append('RoW' + '(' + str(i) + ')')\n",
    "    # put all of that in dictRoW\n",
    "    for i in range(0, len(unique_RoWs)):\n",
    "        self.dictRoW[listname[i]] = unique_RoWs[i]\n",
    "    try:\n",
    "        # if RoWs are empty because processes from ecoinvent are too described\n",
    "        del [[k for k in self.dictRoW.keys() if len(self.dictRoW[k]) == 0][0]]\n",
    "    except IndexError:\n",
    "        pass\n",
    "    for keys in dictactrow:\n",
    "        for keys2 in self.dictRoW:\n",
    "            if dictactrow[keys] == self.dictRoW[keys2]:\n",
    "                dictactrow[keys] = keys2\n",
    "    RoW_matrix = pd.DataFrame(list(dictactrow.values()), index=list(dictactrow.keys()), columns=['RoW_geography'])\n",
    "    self.PRO_f = self.PRO_f.merge(RoW_matrix, left_on='activityNameId', right_on=RoW_matrix.index, how='outer')\n",
    "    self.PRO_f.index = self.PRO_f.activityId + '_' + self.PRO_f.productId\n",
    "    self.PRO_f = self.PRO_f.reindex(self.processes_in_order)\n",
    "    self.PRO_f.io_geography.update(self.PRO_f.RoW_geography[self.PRO_f.io_geography == 'RoW'])\n",
    "    self.PRO_f = self.PRO_f.drop('RoW_geography', axis=1)\n",
    "    # might be some RoW or empty lists left in PRO_f\n",
    "    self.PRO_f.io_geography[self.PRO_f.io_geography == 'RoW'] = 'GLO'\n",
    "    self.PRO_f.io_geography.loc[[i for i in self.PRO_f.index if type(self.PRO_f.io_geography[i]) == list]] = 'GLO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prod_country =  pd.DataFrame(\n",
    "    self.X_io.todense(),\n",
    "    index=pd.MultiIndex.from_product(\n",
    "        [self.regions_of_IO, self.sectors_of_IO],\n",
    "        names=['region', 'sector']\n",
    "    ),\n",
    "    columns=['production']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_products_IO = len([i for i in exiobase.get_sectors()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prod_country = exiobase.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Paddy rice', 'Wheat', 'Cereal grains nec', 'Vegetables, fruit, nuts',\n",
       "       'Oil seeds', 'Sugar cane, sugar beet', 'Plant-based fibers',\n",
       "       'Crops nec', 'Cattle', 'Pigs',\n",
       "       ...\n",
       "       'Paper for treatment: landfill',\n",
       "       'Plastic waste for treatment: landfill',\n",
       "       'Inert/metal/hazardous waste for treatment: landfill',\n",
       "       'Textiles waste for treatment: landfill',\n",
       "       'Wood waste for treatment: landfill',\n",
       "       'Membership organisation services n.e.c. (91)',\n",
       "       'Recreational, cultural and sporting services (92)',\n",
       "       'Other services (93)', 'Private households with employed persons (95)',\n",
       "       'Extra-territorial organizations and bodies'],\n",
       "      dtype='object', name='sector', length=200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exiobase.get_sectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listmatrixxxx = []\n",
    "listlisteeee = []\n",
    "listdffff = []\n",
    "\n",
    "for k in range(0, len(list(self.dictRoW.keys()))):\n",
    "    listmatrixxxx.append('matrixxxx' + str(k))\n",
    "    listlisteeee.append('listeeee' + str(k))\n",
    "    listdffff.append('dfff' + str(k))\n",
    "    listdrop = []\n",
    "    \n",
    "    for i in range(0, len(self.dictRoW)):\n",
    "        listadd = []\n",
    "        for j in range(0, len(io_regions)):\n",
    "            if io_regions[j] not in list(dictRoW.values())[i]:\n",
    "                listadd.append(self.listcountry[j])\n",
    "        listdrop.append(listadd)\n",
    "\n",
    "for i in range(0, len(list(self.dictRoW.keys()))):\n",
    "    listadd = []\n",
    "    listmatrixxxx[i] = self.total_prod_country.drop(listdrop[i], axis=0, level=0)\n",
    "    for k in range(0, self.number_of_products_IO):\n",
    "        somme = 0\n",
    "        for j in range(0, len(listmatrixxxx[i]), self.number_of_products_IO):\n",
    "            somme += listmatrixxxx[i].iloc[j + k, 0]\n",
    "        listadd.append(somme)\n",
    "    listlisteeee[i] = listadd\n",
    "    listdffff[i] = pd.DataFrame(listlisteeee[i], listact, [list(self.dictRoW.keys())[i]])\n",
    "    self.total_prod_RoW = self.total_prod_RoW.join(listdffff[i], how='outer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('3.9.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ac9ca70475864b81d4b10ec8af33fc4d216487d5a0e75614771e743db6d6a64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
